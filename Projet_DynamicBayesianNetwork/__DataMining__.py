## Présentation de la base de données
"""""
La base de données sélectionnée dans le cadre de cet ouvrage est une base de données publique (open-source) issue du programme de recherche (Smart Grid Smart City) dirigé par Ausgrid, un opérateur de distribution d’énergie en Australie en coopération avec le département du ministère de l’énergie australien. Cette base de données créée en 2014 et mise à jour en 2022, contient les données de 78720 clients.
""""

## Sujet de recherche
"""
APPROCHE PROBABILISTE DE LA PREVISION LA CONSOMMATION D’ENERGIE A L’AIDE D’UN RESEAU BAYESIEN DYNAMIQUE 
"""

### Variables :

"""
- `CD_KEY` : Unique identification of Customer consumption electricity at a specific time.
- `CUSTOMER_KEY` : Generic numerical identifier of household. Can be used for linking data from same household across SGSC Customer data resources.
- `CALENDAR_KEY` : Generic numerical identifier allocated to a specific time and date. Used to indicate readings in both the Home Appliance Network appliance reading resource, the  interval meter data readings, and the separate dataset of Electric Vehicle readings.
- `READING_TIME` : Date and time of Home Area Network appliance  cumulative energy usage reading.
- `BIN_PEAK` : Year for which VWS data were computed.
- `EVENT_KEY` : Generic numerical identifier of a peak network event as called by the electricity retailer or distribution business. Each event is individualised by date and time of occurrence, and by the peak event tariff applied at the time  Dynamic Peak Price (DPP) or Dynamic Peak Rebate (DPR). (%)
- `GENERAL_SUPPLY_KWH` : Interval reading of electricty use in kWh on a general supply tariff
- `CONTROLLED_LOAD_KWH` : Interval reading of electricty use in kWh on a controlled load tariff
- `GROSS_GENERATION_KWH` : Total electricty, in kWh, generated by household PV panels fed back into the network 
- `NET_GENERATION_KWH` : Total electricty, in kWh, generated by household PV panels, minus household consumption of electricty (kWh)
- `OTHER_KWH` : Other electricity generation detected, in kWh, not fed back into the network
- `PLUG_NAME` : Type of  Home Area Network appliance or room electricty usage readings being measured (deg C)
- `READING_VALUE` : The numerical value, measured in kWh of energy usage at time of reading as indicated by the Home Area Network plug reading
- `RECORD_COUNT` : Indicates the number of readings taken by the Home Area Network plug at the time specified 
- `ACTUAL_KWH` : DPR customer's actual usage in kWh during peak network event as called by the electricity retailer or distribution business
- `BASELINE_KWH` : DPR customer's usage in kWh preceding peak network event as called by the electricity retailer or distribution business
- `REBATE_AMOUNT` : Rebate amount in Australian dollars per event 
- `RECORD_COUNT` : Indicates the number of readings taken by the Home Area Network plug at the time specified.
- `ASSRTD_CLIMATE_ZONE_CD` : Details climate zone, as per those used by Australian Building Codes Board by numerical code
- `SMART_METER_INSTALLATION_DATE` : Details the date of Smart Meter installation.
- `OPERATION_START_DATE` : Customer tariff product trial period begins
- `OPERATION_FINISH_DATE` :Customer tariff product trial period ends

"""

# Importer les librairies
import pandas as pd
import numpy as np
import warnings
import os
import math
import matplotlib.pyplot as plt
import seaborn as sns
#from timeseriesql_matplotlib import MatplotlibTQL as mp
#from timeseriesql.backends.csv_backend import CSVBackend

## Importer les bases de données
# Importer les bases de données
DbSGSC = "DbSGSC.csv"
Model_GROSS_GENERATION_KWH = "Model _GROSS_GENERATION_KWH.csv"
Model_CONTROLLED_LOAD_KWH = "Model_CONTROLLED_LOAD_KWH.csv"
Model_EVENT_KEY = "Model_EVENT_KEY.csv"
Model_GENERAL_SUPPLY_KWH = "Model_GENERAL_SUPPLY_KWH.csv"
Model_NET_GENERATION_KWH = "Model_NET_GENERATION_KWH.csv"
Model_OTHER_KWH = "Model_OTHER_KWH.csv"
sgsc_cthanplug_readings = "sgsc-cthanplug-readings.csv"
sgsc_ctpeak_event_response = "sgsc-ctpeak-event-response.csv"
sgsc_ct_customer_household_data_revised = "sgsc-ct_customer-household-data-revised.csv"


## Charger les bases de données
# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_GENERATION_KWH = pd.read_csv(Model_GROSS_GENERATION_KWH, sep=";")
df_EUIReadings_LOAD_KWH = pd.read_csv(Model_CONTROLLED_LOAD_KWH, sep=";")
df_EUIReadings_EVENT_KEY = pd.read_csv(Model_EVENT_KEY, sep=";")
df_EUIReadings_SUPPLY_KWH = pd.read_csv(Model_GENERAL_SUPPLY_KWH, sep=";")
df_EUIReadings_NET_GENERATION_KWH = pd.read_csv(Model_NET_GENERATION_KWH, sep=";")
df_EUIReadings_OTHER_KWH = pd.read_csv(Model_OTHER_KWH, sep=";")

# Base de données ~ Home Area Network Plug Readings
df_HANPlugReadings = pd.read_csv(sgsc_cthanplug_readings, sep=",")

# Base de données ~ Peak Events
df_PeakEvents = pd.read_csv(sgsc_ctpeak_event_response, sep=";")

# Base de données ~ Customer Household Data
df_CustoHouseData = pd.read_csv(sgsc_ct_customer_household_data_revised, sep=";")

# Base de données ~ Smart Grid Smart City Consolidée
df_SGSC = pd.read_csv(DbSGSC, sep=",")

# Base de données
# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_GENERATION_KWH.columns = df_EUIReadings_GENERATION_KWH.columns.str.strip()
df_EUIReadings_GENERATION_KWH["CD_KEY"] = df_EUIReadings_GENERATION_KWH["CUSTOMER_ID"].astype(str) + "_" + df_EUIReadings_GENERATION_KWH["CALENDAR_KEY"].astype(str)
df_EUIReadings_GENERATION_KWH.head(10)

# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_LOAD_KWH.columns = df_EUIReadings_LOAD_KWH.columns.str.strip()
df_EUIReadings_LOAD_KWH["CD_KEY"] = df_EUIReadings_LOAD_KWH["CUSTOMER_ID"].astype(str) + "_" + df_EUIReadings_LOAD_KWH["CALENDAR_KEY"].astype(str)
df_EUIReadings_LOAD_KWH.head(10)

# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_EVENT_KEY.columns = df_EUIReadings_EVENT_KEY.columns.str.strip()
df_EUIReadings_EVENT_KEY["CD_KEY"] = df_EUIReadings_EVENT_KEY["CUSTOMER_ID"].astype(str) + "_" + \
                                     df_EUIReadings_EVENT_KEY["CALENDAR_KEY"].astype(str)
df_EUIReadings_EVENT_KEY.head(10)


# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_SUPPLY_KWH.columns = df_EUIReadings_SUPPLY_KWH.columns.str.strip()
df_EUIReadings_SUPPLY_KWH["CD_KEY"] = df_EUIReadings_SUPPLY_KWH["CUSTOMER_ID"].astype(str) + "_" + df_EUIReadings_SUPPLY_KWH["CALENDAR_KEY"].astype(str)
df_EUIReadings_SUPPLY_KWH.head(10)

# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_NET_GENERATION_KWH.columns = df_EUIReadings_NET_GENERATION_KWH.columns.str.strip()
df_EUIReadings_NET_GENERATION_KWH["CD_KEY"] = df_EUIReadings_NET_GENERATION_KWH["CUSTOMER_ID"].astype(str) + "_" + df_EUIReadings_NET_GENERATION_KWH["CALENDAR_KEY"].astype(str)
df_EUIReadings_NET_GENERATION_KWH.head(10)

# Base de données ~ Electricty Use Interval Readings (EUIReading)
df_EUIReadings_OTHER_KWH.columns = df_EUIReadings_OTHER_KWH.columns.str.strip()
df_EUIReadings_OTHER_KWH["CD_KEY"] = df_EUIReadings_OTHER_KWH["CUSTOMER_ID"].astype(str) + "_" + df_EUIReadings_OTHER_KWH["CALENDAR_KEY"].astype(str)
df_EUIReadings_OTHER_KWH.head(10)


# Base de données ~ Home Area Network Plug Readings
df_HANPlugReadings.columns = df_HANPlugReadings.columns.str.strip()
df_HANPlugReadings["CD_KEY"] = df_HANPlugReadings["CUSTOMER_ID"].astype(str) + "_" + df_HANPlugReadings["CALENDAR_KEY"].astype(str)
df_HANPlugReadings.head(10)

# Base de données ~ Customer Household Data
df_CustoHouseData.columns = df_CustoHouseData.columns.str.strip()
df_CustoHouseData.head(10)

# Base de données ~ Smart Grid Smart City Consolidée
df_SGSC.columns = df_SGSC.columns.str.strip()
df_SGSC.head(10)


# Statistiques descriptives
# Fonction pour faire l'inventaire des bases de donnnées

def inventaire_database(data, name):
    df = pd.DataFrame(data)
    Matrice = {
        'Nom': name,
        'NbreLigne': df.shape[0],
        'NbreColonne': df.shape[1],

    }
    if "CUSTOMER_ID" in df.columns:
        Matrice['Individus'] = len(df['CUSTOMER_ID'].unique())
        Matrice['DureeObsMax'] = round(df['CUSTOMER_ID'].value_counts().max())

    elif "CUSTOMER_KEY" in df.columns:
        Matrice['Individus'] = len(df['CUSTOMER_KEY'].unique())
        Matrice['DureeObsMax'] = round(df['CUSTOMER_KEY'].value_counts().max())
    else:
        Matrice['Individus'] = "NaN"

    return Matrice


listes_dataframes = [
    (df_EUIReadings_GENERATION_KWH, 'df_EUIReadings_GENERATION_KWH'),
    (df_HANPlugReadings, 'df_HANPlugReadings'),
    (df_PeakEvents, 'df_PeakEvents'),
    (df_CustoHouseData, 'df_CustoHouseData'),
    (df_SGSC, 'df_SGSC')
]

resultats = []
for data, name in listes_dataframes:
    resultats.append(inventaire_database(data, name))

resultats_df = pd.DataFrame(resultats)
resultats_df


# Création d'une fonction pour trouver le type de chaque variable
def TypeVariable(dataframe):
    resultat = {}
    df = pd.DataFrame(dataframe)

    for col in df.columns:
        matrice = {
            "dtype": df[col].dtypes
        }
        resultat[col] = matrice
    resultat = pd.DataFrame(resultat)
    return resultat.T

TypeVariable(df_EUIReadings_GENERATION_KWH)

# Type des fonction
TypeVariable(df_SGSC)

# Clé de fusion et de tri

key_variables =["CD_KEY", "CUSTOMER_ID", "CALENDAR_KEY", "READING_DATETIME"]
key_merge = "inner"

# Tri des Bases de données
df_EUIReadings_SUPPLY_KWH = df_EUIReadings_SUPPLY_KWH.sort_values(key_variables)
df_EUIReadings_LOAD_KWH = df_EUIReadings_LOAD_KWH.sort_values(key_variables)

# Fusion des bases de données
df_merge_0 = pd.merge(df_EUIReadings_SUPPLY_KWH, df_EUIReadings_LOAD_KWH, on=key_variables, how=key_merge)
df_merge_0

# Ordre de la réorganisation
NewOrder_Variable = ['CD_KEY', 'CUSTOMER_ID', 'CALENDAR_KEY', 'READING_DATETIME', 'GENERAL_SUPPLY_KWH', 'CONTROLLED_LOAD_KWH']
df_merge_0 = df_merge_0.reindex(NewOrder_Variable, axis=1)
df_merge_0.head(10)

len(df_merge_0["CUSTOMER_ID"].unique())

# Fonctions pour connaitres les individus les mieux représentés$
plt.figure(figsize=(20, 17))
BestIndividuals = pd.DataFrame(df_merge_0["CUSTOMER_ID"].value_counts())
plt.barh(BestIndividuals.index.astype(str), sorted(BestIndividuals["count"].tolist()))
plt.show()


# Tableau de Statistiques descriptives
df_merge_0[["GENERAL_SUPPLY_KWH", "CONTROLLED_LOAD_KWH"]].describe()


# Convertir les variables CUSTOMER_ID et CALENDAR_KEY en variables qualitatives
df_merge_0["CUSTOMER_ID"] = df_merge_0["CUSTOMER_ID"].astype("str")
df_merge_0["CALENDAR_KEY"] = df_merge_0["CALENDAR_KEY"].astype("str")


# Convertir la variable READING_DATETIME en variable date
df_merge_0["READING_DATETIME"] = pd.to_datetime(df_merge_0["READING_DATETIME"])


# Création des variables YEAR, MONTH et DAY
df_merge_0["YEAR"] = df_merge_0["READING_DATETIME"].dt.year
df_merge_0["MONTH"] = df_merge_0["READING_DATETIME"].dt.month
df_merge_0["DAY"] = df_merge_0["READING_DATETIME"].dt.day
df_merge_0["YEAR_MONTH"] = df_merge_0["YEAR"].astype(str) + "_" + df_merge_0["MONTH"].astype(str)

# Vérification des nouvelles colonnes
print(df_merge_0.info())
df_merge_0.head(10)

# Transformation du dataframe merge par customer_id
df_groupby_Customer = df_merge_0.groupby(["CUSTOMER_ID"])[["GENERAL_SUPPLY_KWH", "CONTROLLED_LOAD_KWH"]].mean()

# Transformation du dataframe merge par groupby Year

ListVariable_YEAR = ["CUSTOMER_ID",	"YEAR",	"GENERAL_SUPPLY_KWH",	"CONTROLLED_LOAD_KWH"]
df_merge_0_transform_YEAR = df_merge_0[ListVariable_YEAR]
df_groupby_YEAR = df_merge_0_transform_YEAR.groupby(["CUSTOMER_ID", "YEAR"])[["GENERAL_SUPPLY_KWH", "CONTROLLED_LOAD_KWH"]].mean()

# Transformation du dataframe merge par groupby Year et Month
ListVariable_YEAR_MONTH = ["CUSTOMER_ID",	"YEAR_MONTH",	"GENERAL_SUPPLY_KWH",	"CONTROLLED_LOAD_KWH"]
df_merge_0_transform_YEAR_MONTH = df_merge_0[ListVariable_YEAR_MONTH]
df_groupby_YEAR_MONTH = df_merge_0_transform_YEAR_MONTH.groupby(["CUSTOMER_ID", "YEAR_MONTH"])[["GENERAL_SUPPLY_KWH", "CONTROLLED_LOAD_KWH"]].mean()

fig, ax = plt.subplots(figsize=(8, 4))

# Tracé de l'histogramme avec seaborn (remplacement de `distplot` par `histplot`)
sns.histplot(df_groupby_Customer["GENERAL_SUPPLY_KWH"], bins='auto', kde=True, color='#2E6A9D', ax=ax)

# Ajout des lignes de la moyenne et de la médiane
mean = df_groupby_Customer["GENERAL_SUPPLY_KWH"].mean()
median = df_groupby_Customer["GENERAL_SUPPLY_KWH"].median()

ax.axvline(mean, color='red', linestyle='--', label='Mean')
ax.axvline(median, color='green', linestyle='-.', label='Median')

# Ajout du texte informatif sur la moyenne et la médiane
ax.text(0.95, 0.95, f'Mean: {mean:.2f}\nMedian: {median:.2f}',
        transform=ax.transAxes, fontsize=10, va='top', ha='right')

# Ajout de la légende et du titre
ax.legend(loc='upper left')
ax.set_title("Distribution of Electricity Consumption")

# Affichage du graphique
plt.tight_layout()
plt.show()

variable = 'GENERAL_SUPPLY_KWH'

df_groupby_YEAR_MONTH_pivot = df_groupby_YEAR_MONTH.pivot_table(index='CUSTOMER_ID', columns='YEAR_MONTH', values=variable, aggfunc='first')
df_groupby_YEAR_MONTH_pivot.columns = date_order
plt.figure(figsize=(8, 4))
for idx, row in df_groupby_YEAR_MONTH_pivot.iterrows():
    plt.plot(df_groupby_YEAR_MONTH_pivot.columns, row, label=idx, linestyle='--')

plt.title(f"Évolution de la consommation mensuelle d'électricité par individu")
plt.xlabel('Année_Mois')
plt.ylabel(variable)
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

# Réinitialisation de l'index pour convertir CUSTOMER_ID en colonne
df_long = df_groupby_YEAR_MONTH_pivot.reset_index().melt(id_vars="CUSTOMER_ID",
                                                         var_name="YEAR_MONTH",
                                                         value_name="VALUE")


# Suppression des valeurs NaN
df_long.dropna(inplace=True)

# Création du box plot avec Seaborn
plt.figure(figsize=(15, 6))
sns.boxplot(x="YEAR_MONTH", y="VALUE", data=df_long)

# Rotation des labels pour améliorer la lisibilité
plt.xticks(rotation=90)

# Ajout du titre et des labels
plt.title("Box Plot du niveau de consommation mensuelle par date")
plt.xlabel("Date (YEAR_MONTH)")
plt.ylabel("Valeurs")
plt.grid(True)
plt.show()
